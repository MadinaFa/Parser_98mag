Цель проекта — создать парсер, который автоматически собирает информацию о событиях с сайта 98mag.kz из раздела «События».

Парсер должен:

извлекать заголовок события, ссылку и дату публикации;

переходить на страницу каждого события;

сохранять полученные данные в структурированном виде;

быть готовым к масштабированию (расширению на другие категории, сайты, типы данных).

Обоснование задачи:
Такой парсер может быть использован для мониторинга событий города, создания агрегаторов новостей, подписочных сервисов или последующей интеграции во внутренние системы аналитики.

Структура проекта и архитектура

Проект состоит из одного файла:

98mag.py          # Основной скрипт парсинга


Код структурирован таким образом, чтобы:

легко было выделить функции в дальнейшем;

заменить источник данных (другой сайт);

интегрировать парсер в класс или более крупную систему.

Используемые технологии

Проект использует:

Python 3.10+

requests — для загрузки HTML-страниц

lxml — для разбора HTML и поиска элементов

Инструкция по запуску
1. Клонировать репозиторий (если нужно)
git clone <ссылка-на-репозиторий>
cd Parser

2. Создать виртуальное окружение
python -m venv .venv

3. Активировать окружение

Windows:

.venv\Scripts\activate


macOS/Linux:

source .venv/bin/activate

4. Установить зависимости
pip install requests lxml cssselect



5. Запустить проект
python 1.py

Выходные данные

Сейчас результат выводится в консоль:

заголовок события

ссылка

дата

При необходимости можно добавить:

сохранение в CSV

сохранение в JSON

сохранение в Excel

запись в базу данных

Например, сохранить список событий в JSON:

import json

with open("events.json", "w", encoding="utf-8") as f:
    json.dump(result, f, ensure_ascii=False, indent=4)
